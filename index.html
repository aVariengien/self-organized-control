<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Towards self organized control</title>
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300italic,700,700italic">

	<!-- CSS Reset -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.css">

	<!-- Milligram CSS -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/milligram/1.4.1/milligram.css">

	<link rel="stylesheet" href="style/style.css">
	
  </head>
  
  <body class="margin-m">
  <div class="row">
  <div class="column column-60 column-offset-20">


	<h1> Towards self organized control </h1>
	<h3 class="nobold"> Using neural cellular automata to robustly control a cartpole agent</h3>
	<h4 class="nobold"> Alexandre Variengien <sup>1,2,3</sup>, Stefano Nichele<sup>1,2,*</sup>, Tom Glover<sup>1</sup>, Sidney Pontes-Filho<sup>1</sup></h4>
	<small class="nobold"><sup><small>1</small></sup> Department of Computer Science, Oslo Metropolitan University, Oslo (Norway)  <br>
					   <sup><small>2</small></sup> Department of Holistic Systems, Simula Metropolitan Centre for Digital Engineering, Oslo (Norway) <br>
					   <sup><small>3</small></sup> Department of Computer Science, École Normale Supérieure de Lyon, Lyon (France) <br>
					   <sup><small>*</small></sup> Corresponding author: <a href="mailto:stenic@oslomet.no">stenic@oslomet.no</a>
	</small>
	
	<video autoplay loop width="750" class="center">
		<source src="videos/grid_and_envi/noise_no_damage_crop.mp4"
				type="video/mp4" class="center" >
		Sorry, your browser doesn't support embedded videos.
	</video>
	<div class="caption">A neural cellular automaton controling a cartpole agent.</div>

	<h2 class="margin-m"> Introduction </h2>
		<p>
			One of the most remarkable feat of life is the developmental process leading to the emergent complexity of the human brain from 
			a single cell. The field of neurodevelopment (i.e., the development of the nervous system) has been investigating this problem for 
			decades. These studies led to the discovery of the intricate mechanisms by which gradients of chemicals and local cell interactions
			shape the differentiation of pre-neural cells and the organization of their connections. [<b> citation needed</b>]
		</p>
		<p>
			Even after the brain is considered fully grown, its developmental process does not stop. New neurons are formed 
			continuously until death, and the shape and the strength of their connections change.[<b> citation needed</b>] 
			Such neural plasticity is influenced by the sensory inputs received by the individual and is considered to be 
			at the root of the emergence of intelligence. In addition to the ability to cope with a changing environment, 
			plasticity provides a remarkable robustness. For example, the processing of visual information can be deferred 
			to the auditive cortex if the first is impaired. [<b> citation needed</b>]
		</p>
		<p>
			The neural plasticity can be considered as a part of the whole biological mechanism governing homeostasis of both 
			shape and function. This conceptual proximity is also justified by biological evidence such as the recent discovery 
			of the role of electrical activity during morphogenesis. In particular, the same ion channels are used both for local 
			communication between non neural cells during embryogenesis and in the neurons to carry action potentials. [<b> Mike Levin et al. on flatworms</b>]
			More generally, there seems to exists a continuum between the phenomena we usually call <i> growing</i>, 
			<i> learning</i> and <i>computing</i>. 
			Each of these abilities may be considered a different aspect of the same underlying self-organizing system.
		</p>
		<p>
			Moreover, there is evidence that the DNA does not encode precise details of the resulting neural network. 
			There is an information gap between the size of the DNA and the complexity of the neural network, generally 
			referred to as <i>genomic bottleneck</i> [<b>A critique of pure learning ..., Anthony M. Zador</b>]. 
			The DNA, through the shape of the proteins it encodes, specifies the local behavior of cells. The neural 
			network is then a structure that emerges through these local interactions and yield a useful biological 
			processing of the inputs received by the senses. [<b>The Challenge Of Complexity, Wolfgang Banzhaf</b>]
		</p>
		
		<p>
			Despite the crucial role of growth in the emergence of intelligence, modern advances in artificial neural 
			networks mainly focus on the handcrafted design of static map neural connections. During the phase 
			called<i>learning</i>—that is in fact quite far from the biological sense of this 
			word [<b>A critique of pure learning ..., Anthony M. Zador</b>]—the connections of this architecture are 
			optimized to reduce the error on the task to solve.
		</p>
		
		<p>
			Some effort has been made to include an automatic process to incrementally design neural network architectures. 
			These techniques include the use of genetic algorithms <b>[citation NEAT]</b>, pruning of connection 
			<b>[citation https://medvet.inginf.units.it/publications/2021-c-nmpzn-effects/]</b> or with the introduction of Growing Neural Networks. 
			<b>[https://direct.mit.edu/isal/proceedings/isal2020/32/473/98437, Growing Artificial Neural Networks, John Mixter and Ali Akoglu] </b>
			Nonetheless, in these works the process is a tool of navigating the topological parameter space, rather then treating the learning 
			as a developmental problem.
		</p>

		<p>
			 In this work we attempt at bridging the gap between growth and computation by using neural cellular automaton (CA) 
			 <b>[Growing NCA, https://core.ac.uk/download/pdf/147570059.pdf]</b>. This is a spatially distributed system composed of 
			 cells that interact through local interaction. Their update rule consists in an artificial neural networks and thus 
			 can be optimized through the classical and efficient gradient descent-based techniques. Even if the learning process 
			 is still happening through a procedure exterior to the system, the local rules encode both the developmental 
			 process—the transformation from a random grid to a configuration suitable for computation—and the information processing itself. 
			 We found that the cells were able to transmit and combine in a meaningful way the information from input cells to output cells 
			 used as a readout. The system demonstrates long-term stability and robustness to noise and damage. We illustrate these 
			 abilities on a simple control task as a proof of concept.
		</p>
		
	<h2> The pole balancing task </h2>
		
		<p>
		The cart-pole problem is a commonly used toy problem in the reinforcement learning community. In this
		environment, an agent can observe the pole angle and angular velocity, the cart position, and its linear velocity.
		Based on these observations, it must decide whether to apply a force on the left or the right of the cart in order
		to maximize the time spent with the pole on the top.
		
		We chose this problem because of its low number of input and output that enables us to
		use a small-sized grid and an easy experimentation environment.
		</p>

	<h2> Cell state </h2>
		<p>
			There are 3 types of cells in a grid: the normal cells, the input, and output cells.
		</p>
		<p>
			The state of each cell is composed of 6 channels. The first is the <i> information channel</i> where meaningful
			input and output information transit. The second is identifying the inputs: it is equal to 1 in the input cell, 0 elsewhere.
			The third is similar for the outputs. The last three are hidden channels.
		</p>
		<p>
			The state of the input cell cannot be changed, the information channel is set to the value to input at this cell
			and the other channel expects the output identifier is set to 1.
			
			The values of the information channel of the output cells are used as the output of the system to be optimized
			to solve the task.
		</p>

		<h4> Input encoding </h4>
		<p>
			For this task, we use redundancy in the inputs: each of the 4 physical observations of the environment is linked to 2 input cells.
			We thought it could improve the opportunity for information combination and robustness. 
			Note that the type of information contained in the input is not directly provided. To know which observation 
			each input cell encodes must be recover from the spatial position of the inputs or from the value of the information channel.
		</p>

		<h4> Cell position </h4>
		<p>
			The 8 inputs are arranged in an octagonal shape (dotted line) with the two outputs being offset by 2 cells from the center of the octagon.
			We chose this configuration to ensure an equal distribution of the distance between each input information and output.
			<div>
			<img src = "img/io_position.png" width="300" class="center" >
			</div>
			<div class="caption">The position of input (in red) and output cells (in yellow).</div>
			
		</p>
	
	<h2> Model </h2>
		<p>
		Except the design of the cell states, the neural CA architecture we used is similar to the one described here. [<b>Self-classifying MNIST Digits</b>]
		The perception layer is composed of 20 learnable 3x3 filters, and the single hidden layers counts 30 units.
		In total our model has 1854 learnable parameters.
		</p>
	<h2> Training procedure </h2>
		<p>
		Our model can be abstracted as a black box function that takes inputs (that will be fed to the information channel of input cells)
		and transform them in outputs (the information channel of output cells). This function is differentiable with respect to its
		parameters (the neural network used as update rule) and thus they can be optimized with classical gradient descent techniques.
		In this cased we used the Adam optimized provided by the TensorFlow library. 
		
		To tackle the cart-pole problem, we used Deep Q-learning [<b>citation</b>] where the usual artificial neural network is seamlessly replace by the neural CA.
		</p>
		<h4> Loss function </h4>
			<p>
			The loss function for the task is the L2 loss between the output and the target.
			To achieve long term stability and we added a penalty for 
			cells that have channels value out of bound [-5,5].
			

			<div><img src = "img/loss_formula.png" width="100%" class="center"  ></div>

			<div class="caption">N is the size of the grid, lambda a parameters to control the amount of overflow penalty.</div>


			</p>
		<h4>Model initialization </h4>
			<p>
				We found that when trained directly the model was stuck in a local minimum where it outputted constant values, no matter
				the state of the inputs.
				We think that this is due to the fact that the intermediate cells between inputs lead to a vanishing to the gradient as
				in vanilla Recurrent Neural Networks.
			</p>
			<p>
				To solve this problem, we first optimize the neural CA for an easier task: 
				both outputs were optimized to compute the mean of the inputs. 
				We found that it was able to learn with a reasonably low error after several thousand learning steps.
			</p>
			<p>
				This initialization enables the neural CA to learn to stabilize the state of the cells, make an information link 
				from input to output, and an primitive combination of the input values at the output cells.
			</p>
		<h4> Robustness </h4>
			<p>
				To learn to recover from damage, before each learning step the grid has 0.5 probability of receiving damage.
				
				A damage consist in the states of the cells in a circle of the grid replaced by uniform random values in [-1,1], as shown
				in black below. Note that a damage impact all channel that can be changed and that input are not affected by damage while outputs are.
				<div><img src="img/damage.png" width="500" class="center" ></div>
				<div class="caption">
					A damage shown on the information channel. The shape of the damage is an irregular circle due to rasterization effect.
				</div>
			</p>
	<h2> Results </h2>
	<p>
	We ran the training procedure for around 200k gradient descent step and several hundreds of environment simulation. Note
	that the hyperparamters for the training were not optimized and we mainly aimed at solving the task, not learning efficiency.
	</p>
	<p>
		Our model was able to solve the cartpole problem and achieve long-term stability of both
		the pole balancing and of the state of the CA.
		It was able to balance the pole for more than 10k simulation steps. A video of 9 independent
		runs for 1000 simulation steps is shown below.
	</p>
	<br>
	

	<video autoplay loop width="600" class="center">
		<source src="videos/mosaics/mosaic_no_damage_no_noise_small.mp4"
				type="video/mp4" width=100 class="center" >
		Sorry, your browser doesn't support embedded videos.
	</video>

	<div class="caption">9 independent runs of the final model. </div>
	
	
	
	<!--
	and enables great robustness such as rewiring some part
	of 
	
	Despites the complexity of this phenomenon and the crucial role it plays in the emergence of the 
	abilities of the brain once grown and it 
	
	
	</p>
	
	Here we argue that this 
	
	* Functional homeostasis
	* Indirect encoding of the way to solve the task
	* development throught local interaction -> could lead to adaptation and here robustness
	* low information encoding of complex task. The complexity can emerge in the spatial shape of the interaction
	 while the information encoding the local law are low info // genomic bottleneck
	* abstract computing substrate 
	* Growing / pruning of ANN
	* continuity growing / computing -> non neural cells precusor of neural activity -->
	 
	
	
	
  </div>
  </div>
  </body>