<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Towards self organized control</title>
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300italic,700,700italic">

	<!-- CSS Reset -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.css">

	<!-- Milligram CSS -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/milligram/1.4.1/milligram.css">

	<link rel="stylesheet" href="style/style.css">
	
  </head>
  
  <body class="margin-m">
  <div class="row">
  <div class="column column-60 column-offset-20">


	<h1> Towards self organized control </h1>
	<h3 class="nobold"> Using neural cellular automata to robustly control a cartpole agent</h3>
	<h4 class="nobold"> Alexandre Variengien <sup>1,2,3</sup>, Stefano Nichele<sup>1,2,*</sup>, Tom Glover<sup>1</sup>, Sidney Pontes-Filho<sup>1</sup></h4>
	<small class="nobold"><sup><small>1</small></sup> Department of Computer Science, Oslo Metropolitan University, Oslo (Norway)  <br>
					   <sup><small>2</small></sup> Department of Holistic Systems, Simula Metropolitan Centre for Digital Engineering, Oslo (Norway) <br>
					   <sup><small>3</small></sup> Department of Computer Science, École Normale Supérieure de Lyon, Lyon (France) <br>
					   <sup><small>*</small></sup> Corresponding author: <a href="mailto:stenic@oslomet.no">stenic@oslomet.no</a>
	</small>
	
	<video autoplay loop width="750" class="center">
		<source src="videos/grid_and_envi/noise_no_damage_crop.mp4"
				type="video/mp4" class="center" >
		Sorry, your browser doesn't support embedded videos.
	</video>
	<div class="caption">A neural cellular automaton controling a cartpole agent.</div>

	<h2 class="margin-m"> Introduction </h2>
		<p>
			One of the most remarkable feats of life is the developmental process leading to the emergent complexity of the human brain from 
			a single cell. The field of neurodevelopment (i.e., the development of the nervous system) has been investigating this problem for 
			decades. These studies led to the discovery of the intricate mechanisms by which gradients of chemicals and local cell interactions
			shape the differentiation of pre-neural cells and the organization of their connections 
			<a class="ref" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2742095/" >[1]  
			<span>Gradients in the Brain: The Control of the Development of Form 
			and Function in the Cerebral Cortex, Stephen N. Sansom and Frederick J. Livesey
			</span></a>.
			
			
			
		</p>
		<p>
			Even after the brain is considered fully grown, its developmental process does not stop. New neurons are formed 
			continuously until death, and the shape and the strength of their connections change.
			Such neural plasticity is influenced by the sensory inputs received by the individual and is considered to be 
			at the root of the emergence of intelligence. In addition to the ability to cope with a changing environment, 
			plasticity provides a remarkable robustness. For example, after a stroke, the neural network reorganizes in a new
			architecture to preserve motor function
			<a class="ref" href="https://www.sciencedirect.com/science/article/pii/S0079612305500360" >[2]<span>Neural plasticity and recovery of function, Nick S.Ward</span></a>.
			It can also adapt to sensory deprivation to extract the most information from the remaining senses. 
			In blind individuals, the processing of auditive information can be partially deferred to the visual cortex, 
			improving their sound localization abilities
			<a class="ref" href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0030027" >[15]
			<span>A Functional Neuroimaging Study of Sound Localization: Visual Cortex 
					Activity Predicts Performance in Early-Blind Individuals, 
							Frédéric Gougoux et al. </span></a>.
		</p>
		<p>
			The neural plasticity can be considered as a part of the whole biological mechanism governing homeostasis of both 
			shape and function. This conceptual proximity is also justified by biological evidence such as the recent discovery 
			of the role of electrical activity during morphogenesis. In particular, the same ion channels are used both for local 
			communication between non neural cells during embryogenesis and in the neurons to carry action potentials 			
			<a class="ref" href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/bem.10104" >[3]  <span>Bioelectromagnetics in morphogenesis, Michael Levin</span></a>.
			
			More generally, there seems to exists a continuum between the phenomena we usually call <i> growing</i>, 
			<i> learning</i> and <i>computing</i>. 
			Each of these abilities may be considered a different aspect of the same underlying self-organizing system.
		</p>
		<p>
			Moreover, there is evidence that the DNA does not encode precise details of the resulting neural network. 
			There is an information gap between the size of the DNA and the complexity of the neural network, generally 
			referred to as <i>genomic bottleneck</i> <a class="ref" href="https://www.nature.com/articles/s41467-019-11786-6" >[4]  <span>A critique of pure learning and what artificial neural networks can learn from animal brains, Anthony M. Zador</span></a>. 
			The DNA, through the shape of the proteins it encodes, specifies the local behavior of cells. The neural 
			network is then a structure that emerges through these local interactions and yields a useful biological 
			processing of the inputs received by the senses
			<a class="ref" href="https://link.springer.com/chapter/10.1007/1-4020-7782-3_11" >[5] <span>The Challenge Of Complexity, Wolfgang Banzhaf</span></a>.
		</p>
		
		<p>
			Despite the crucial role of growth in the emergence of intelligence, modern advances in artificial neural 
			networks mainly focus on the handcrafted design of static map of neural connections. During the phase 
			called <i>learning</i>—that is in fact quite far from the biological sense of this 
			word <a class="ref" href="https://www.nature.com/articles/s41467-019-11786-6" >[4]  
					<span>A critique of pure learning and what artificial 
					neural networks can learn from animal brains, Anthony M. Zador
					</span></a>
				—the connections of this architecture are optimized to reduce the error on the task to solve.
			
		</p>
		
		<p>
			Some effort has been made to include an automatic process to incrementally design neural network architectures. 
			These techniques include the use of genetic algorithms 
					<a class="ref" href="https://ieeexplore.ieee.org/abstract/document/1004508" >[6] 
						<span>Efficient evolution of neural network topologies, K.O. Stanley and R. Miikkulainen</span>
					</a>
			, pruning of connection 
					<a class="ref" href="https://medvet.inginf.units.it/publications/2021-c-nmpzn-effects/" >[7] 
						<span>On the Effects of Pruning on Evolved Neural Controllers for Soft Robots, Giorgia Nadizar et al.</span>
					</a>
			or the introduction of a growing phase in artificial neural networks
					<a class="ref" href="https://direct.mit.edu/isal/proceedings/isal2020/32/473/98437" >[8] 
						<span>Evolving developmental neural networks to solve multiple problems, Julian Francis Miller</span>
					</a>
					<a class="ref" href="https://arxiv.org/abs/2006.06629" >[9] 
						<span>Growing Artificial Neural Networks, John Mixter and Ali Akoglu</span>
					</a>.
			Nonetheless, in these works the process is a tool of navigating the topological parameter space, rather then treating the learning 
			as a developmental problem. 
		</p>
		<p>
			More radical approaches tried to develop an artificial substrate where life-like phenomena could emerge in an open-ended environment
					<a class="ref" href="https://arxiv.org/abs/2101.07627" >[16] 
						<span>Self-Organizing Intelligent Matter: A blueprint for an AI generating algorithm, Karol Gregor and Frederic Besse</span>
					</a>
					<a class="ref" href="https://arxiv.org/abs/2005.03742" >[17] 
						<span>Lenia and Expanded Universe, Bert Wang-Chak Chan</span>
					</a>.
			Despite their great promise, we are still far from recreating the whole evolution process that give rise to intelligence.
		</p>

		<p>
			 In this work, we attempt at bridging the gap between growth and computation by using neural cellular automaton (CA) 
					<a class="ref" href="https://distill.pub/2020/growing-ca/" >[10] 
						<span>Growing Neural Cellular Automata, Alexander Mordvintsev et al.</span>
					</a>.
			 This is a spatially distributed system composed of 
			 cells that interact through local interaction. Their update rule consists of an artificial neural network and thus 
			 can be optimized through classical and efficient gradient descent-based techniques. Even if the learning process 
			 is still happening through a procedure exterior to the system, the local rules encode both the developmental 
			 process—the transformation from a random grid to a configuration suitable for computation—and the information processing itself. 
			 We found that the cells were able to transmit and combine in a meaningful way the information from input cells to output cells 
			 used as a readout. The system demonstrates long-term stability and robustness to noise and damage. We illustrate these 
			 abilities on a simple control task as a proof of concept.
		</p>
		
	<h2> The pole balancing task </h2>
		
		<p>
			The cart-pole problem is a commonly used toy problem in the reinforcement learning community. In this
			environment, an agent controls a cartpole system. It can observe the pole angle and angular velocity, 
			the cart position, and its linear velocity.
			Based on these observations, it must decide whether to apply a force on the left or the right of the cart in order
			to maximize the time spent with the pole up.
			
			We chose this problem because of its low number of inputs and outputs that enables us to
			use a small-sized grid and an easy experimentation environment.
			
			<div>
			<img src = "img/cartepole_envi.png" width="400" class="center" >
			</div>
			<div class="caption">The cartepole environment. The top arrow represents the angular velocity of the pole,
								the bottom arrow, the velocity of the cart.
				</div>
			
		</p>

	<h2> Cell state </h2>
		<p>
			There are 3 types of cells in a grid: the intermediate, the input, and output cells.
		</p>
		<p>
			The state of each cell is composed of 6 channels. The first is the <i> information channel</i> where meaningful
			input and output information transit. The third is identifying the inputs: it is equal to 1 in the input cells, 0 elsewhere.
			The fourth is similar for the outputs. The remaining three are hidden channels.
		</p>
		<p>
			The state of the input cell cannot be changed, the information channel transmit the observation from the environment
			and the other channels except the output identifier are set to 1.
			The values of the information channel of the output cells are used as the output of the system to be optimized
			to solve the task.
		</p>
		<p>
			The meaning of each channel and the different type of cells are represented in the figure below.
		</p>
			<div>
			<img src = "img/cell_states.png" width="700" class="center" >
			</div>
			<div class="caption">The role of the different channels and type of cells. Channels that 
				are fixed are represented in red and in black are channels that can be modified by the update rule.
				</div>

		<h4> Input encoding </h4>
			<p>
				For this task, we use redundancy in the inputs: each of the 4 physical observations of the environment is linked to 2 input cells.
				We thought it could improve the opportunity for information combination and robustness. 
				Note that the type of information contained in the input is not directly provided. To know which observation 
				each input cell encodes, the CA must rely on the spatial position of the inputs or on the value of the information channel.
			</p>
			<p>
				The value of each observation is scaled by a constant factor before being transmitted to the input cell. The choice of the 
				factor corresponding to each observation was chosen to get similar ranges of values in the information channel.
			</p>
		<h4> Cell position </h4>
		<p>
			The 8 inputs are arranged in an octagonal shape (dotted line) with the two outputs being offset by 2 cells from the center of the octagon.
			We chose this configuration to ensure an almost equal distribution of the distance between each input and output.
			<div>
			<img src = "img/io_position.png" width="300" class="center" >
			</div>
			<div class="caption">The position of input (in red) and output cells (in yellow).</div>
			
		</p>
	
	<h2> Model </h2>
		<p>
			Except the design of the cell states, the neural CA architecture we used is similar to the one described for the self-classifying MNIST task 
					<a class="ref" href="https://distill.pub/2020/selforg/mnist/" >[11] 
						<span>Self-classifying MNIST Digits, Ettore Randazzo et al.</span>
					</a>.
			The perception layer is composed of 20 learnable 3x3 filters, and the single hidden layers counts 30 units.
			In total our model has 1854 learnable parameters. 
		</p>
		<p>
			
			As in the original model, the update rule is stochastic: at each step, each cell
			has a 0.5 probability of being updated. This choice is made to avoid temporal synchronization that relies on a centralized clock.
		</p>
	<h2> Training procedure </h2>
		<p>
			Our model can be abstracted as a black box function that takes inputs (that will be fed to the information channel of input cells)
			and transform them in outputs (the information channel of output cells). This function is differentiable with respect to its
			parameters (the neural network used as update rule) and thus they can be optimized with classical gradient descent techniques.
			In this case we used the Adam optimized provided by the TensorFlow library. 
		</p>
		<h4> Algorithm </h4>
		<p>
			To tackle the cart-pole problem, we used Deep Q-learning 
					<a class="ref" href="https://arxiv.org/abs/1312.5602" >[12] 
						<span>Playing Atari with Deep Reinforcement Learning, Volodymyr Mnih et al.</span>
					</a>
			where the usual artificial neural network is seamlessly replaced by the neural CA.
			The deep Q-learning algorithm aims at approaching the expected reward given a state and an action.
			More precisely, the function to be learned is given by:
			
			<div><img src = "img/q_value.png" width="70%" class="center"  ></div>
			<div class="caption">s<sub>t</sub> is the current state and a<sub>t</sub> the action to evaluate. 
				&gamma; is a discount factor. </div> <!-- We used &gamma;=0.95, a usual value for deep Q-learning. -->
			To keep the CA values in the information channel in a range coherent with the other cells, we scale the outputs of the CA by a factor
			of 100 to get the Q-value estimates.
		</p>
		<h4> Environment </h4>
		<p>
			We used the cartpole environment provided by the <a href="https://gym.openai.com/">OpenAI gym library</a>.
			<!-- comment on the custom reward function ? -->
		</p>
		<h4> Loss function </h4>
			<p>
			The loss function for the task is the L2 loss between the output and the target.
			To achieve long term stability and we added a penalty for 
			cells that have channels value out of bound [-5,5]. Note that excepted this overflow condition,
			the states of the intermediate cells are not directly optimized, they are free to evolve insofar as their influence on the outputs
			reduce the error.
			
			<div><img src = "img/loss_formula.png" width="100%" class="center"  ></div>
			<div class="caption">N is the size of the grid, &lambda; a parameter to control the amount of overflow penalty.</div>


			</p>
		<h4> Neural CA training </h4>
			<p>
				As introduced in <a class="ref" href="https://distill.pub/2020/growing-ca/" >[10] 
									<span>Growing Neural Cellular Automata, Alexander Mordvintsev et al.</span>
								</a> 
					we used pool sampling for the states of the neural CA during training.
				We let the CA evolves for a random number from 50 to 60 steps between the update of the input values and the readout of
				the outputs.
			</p>
		
		
		<h4>Model initialization </h4>
			<p>
				We found that when trained directly for the task, the model was trapped in a local minimum where it outputted constant values, no matter
				the state of the inputs.
				We think that this is due to the fact that there needs to be iterated applications of the update rule on each of the cells between the inputs and outputs
				to transmit and modify the information.
				This repeated use of a neural network makes the gradient vanish, as observed
				in vanilla Recurrent Neural Networks
								<a class="ref" href="https://www.worldscientific.com/doi/abs/10.1142/s0218488598000094" >[13] 
									<span>The Vanishing Gradient Problem During Learning Recurrent Neural Nets and Problem Solutions, Sepp Hochreiter</span>
								</a>.
			</p>
			<p>
				To solve this problem, we first optimize the neural CA for an easier task: 
				both outputs were optimized to compute the mean of the inputs. 
				We found that it was able to learn with a reasonably low error after several thousand training steps.
			</p>
			<p>
				This initialization enables the neural CA to learn to stabilize the states of the cells, make an information link 
				from input to output, and a primitive combination of the input values at the output cells. This procedure 
				is similar to what is used in curriculum learning <a class="ref" href="https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf" >[14] 
																		<span>Curriculum Learning, Yoshua Bengio et al.</span>
																  </a>  
								
								where an easy subset of the task is learned before tackling the whole problem.
				Here we didn't used a sub-task as a starting point but a different task that shared common requirements.
			</p>
		<h4> Robustness </h4>
			<h6> Damage </h6>
			<p>
				To learn to recover from damage, we added damage to the grids present in the pool of sample. 
				Each grid has a 0.5 probability of receiving damage.
				
				A damage consist in a circle of the grid replaced by uniform random values in [-1,1], as shown
				in black below. Note that a damage impact all the channels that can be modified and that inputs are not affected by damage while outputs are.
				<div><img src="img/damage.png" width="500" class="center" ></div>
				<div class="caption">
					A damage shown on the information channel. The shape of the damage is an irregular circle due to rasterization effect.
				</div>
			</p>
			<h6> Noise </h6>
			<p>
				Before applying each update, we added a uniform noise. Following what was done in 
				<a class="ref" href="https://distill.pub/2020/selforg/mnist/" >[11] 
					<span>Self-classifying MNIST Digits, Ettore Randazzo et al.</span>
				</a>, 
				we used noisy update to force a long-term stabilization of the
				states of the CA. <!-- since it would learn to cope with perturbation at every step.-->
			</p>
	<h2> Results </h2>
	<p>
	We ran the training procedure for 200k gradient descent steps and several hundreds of environment simulations. Note
	that the hyperparameters for the training were not optimized and we mainly aimed at solving the task, not efficiency.
	</p>
	
	<h4> From estimating Q-values to stable behavior </h4>
	<p>
		To get a persistent control of the 
		cartpole agent, we begin by transmitting the observation of the current state in the input cells. We let the 
		neural CA evolve for a random number of steps between 50 and 60. We take the action
		corresponding to the maximum output value and we input the new observation to the neural CA.
		
		The grid is initialized with uniform random values and the same grid is used during the whole
		simulation.
	</p>
	
	<p>
		Our model was able to solve the cartpole problem and achieve long-term stability of both
		the pole balancing and of the states of the CA.
		It was able to balance the pole for more than 10k simulation steps. A video of 9 independent
		runs for 1000 simulation steps is shown below.
		
		<div>
		<video autoplay loop controls width="750" class="center">
			<source src="videos/mosaics/mosaic_no_damage_no_noise_small.mp4"
					type="video/mp4" width=100 class="center" >
			Sorry, your browser doesn't support embedded videos.
		</video>
		</div>

		<div class="caption">9 independent runs of 1000 steps of the final model. For these runs, the neural CA is not perturbed by noise nor damage. </div>
	</p>
	
	<h4> Resulting neural CA </h4>
	<p>
		Beyond performance, it is interesting to visualize the activities of the 
		neural CA during the control of the cartpole agent. 
	</p>
		
		
		<div>
		<video controls width="750" class="center">
			<source src="videos/grid_and_envi/no_noise_no_damage_small.mp4"
					type="video/mp4" >
			Sorry, your browser doesn't support embedded videos.
		</video>
		</div>
		<div class="caption">
			On the left, the states of the neural CA. 
			For the information channel, negative values are in blue, positive in red. <br>
			Bottom right: the plot of the output values of the neural CA. The vertical dotted lines note when 
			the action that has the maximum expected reward is taken by the cartpole agent.<br>
			Green triangle: LEFT action, orange triangle: RIGHT action.
		</div>
		<p>
			We observe that the first 50 steps lead to a precise spatial organization of the grid. 
			Once stabilized, this global shape will not change during the whole run. This can be thought
			as the developmental part of the neural CA.
		</p>
		<p>
			Then, during the remaining part of the simulation, the spatial activity is changing in phase with 
			the physical observations. This is the computing phase.
		</p>
		<p>
			Note that the output values are always really
			close one. Since the pole is in a balanced state, the difference
			between the expected reward after going left or right is small. Going left then right or going right 
			then left will not yield a great difference in expected reward. 
		</p>
	<h4> Robustness abilities </h4>
	
	<p>
		During training, the neural CA has always at least 50 steps between the update of the inputs, where damage
		can occur,
		and the readout of the output values.
		During testing, we also experimented with a more challenging type of damage
		we called <i>uniformly distributed damage</i> where at each CA steps the grid has a constant
		probability of being damaged.
	</p>
	<p>
		Because this type of damage was more difficult to cope with, we decrease the damage frequency: 
		on average, the CA receive one damage every 4 input updates with uniformly distributed damage
		and one every 2 input updates with the damage used during training.
	</p>
	<p>
		The performance of the neural CA with different perturbation is summarized in the table below.
		The score denote the number of environment steps before the pole fall or the cart hit a wall.
		In each situation, we computed the mean score on 100 independent runs as well as the standard deviation.
	</p>
	<table>
	  <thead>
		<tr>
		  <th>&nbsp;</th>
		  <th>No damage</th>
		  <th>Damage after input update</th>
		  <th>Uniformly distributed damage</th>
		</tr>
	  </thead>
	  <tbody>
		<tr>
		  <th>No noisy update</th>
		  <td> 13273 &pm; 11905</td>
		  <td> 2598.19 &pm; 2241</td>
		  <td> 391.6&pm; 283</td>
		</tr>
		<tr>
		  <th>With noisy update</th>
		  <td>1296.3 &pm; 899</td>
		  <td>739.7 &pm; 473</td>
		  <td>345.7 &pm; 214</td>
		</tr>
	  </tbody>
	</table>
	<div class="caption"> Performance of the cartpole agent with several types of perturbation. The score is the number
		of time steps the cartpole stay balanced without hitting walls. The scores are averaged on 100 runs and are 
		noted <i>mean</i> &pm; <i>standard deviation</i>. </div>
	
	<h6> Resistance to damage </h6>
	
	<p>
	We found that the neural CA was able to maintain its shape and its function despite
	frequent damage. In the video below we can observe how the grid recover its shape after damage.
	Although damage can lead to great perturbations in the output values and so to
	random actions, the agent is still able to stabilize the pole for several hundred steps.
	</p>
	<p>
	Moreover, the neural CA was not trained to recover from uniformly distributed damage, this explains
	the greater diminution in the average score shown in the table.
	
	<div>
	<video controls width="750" class="center">
		<source src="videos/grid_and_envi/no_noise_with_damage_small.mp4"
				type="video/mp4" >
		Sorry, your browser doesn't support embedded videos.
	</video>
	</div>
	
	<div class="caption">
		A neural CA controls a cartpole agent for 500 steps and recovers from grid damages.
		The frequency of damage is on average once every 18 cartpole steps, except for the 
		first steps where it's increased to be able to observe the regeneration of the CA. 
		Damages can be seen around the steps 90 and 110. <br>
		We can observe important drops in the outputs after a damage during the
		time the CA recover.
	</div>
	
	</p>
		Here is an overview of the behavior of the cartpole agent when subject to uniformly distributed damages.
		<div>
		<video controls width="750" class="center">
			<source src="videos/mosaics/mosaic_damageTrue_noiseFalse_small.mp4"
					type="video/mp4" >
			Sorry, your browser doesn't support embedded videos.
		</video>
		</div>
		
		<div class="caption">
			9 independent run of 1000 steps with uniformly distributed damage (on average one damage every 4 cartepole steps).
			When the pole becomes red, it means the simulation is over.
		</div>
	<p>
		
	</p>
	
	<h6> Resistance to noise </h6>
	
	<p>
	The amount of noise added to each update is often of the same order as the difference between the two outputs when the
	pole is in a balanced state. This is why we observe in the video below the green and orange curves
	subject to stochastic variations that lead them to cross many times between each readout. The policy 
	that controls the cartpole agent is thus heavily randomized. Despite the noisy update, the neural CA can produce a probability distribution of actions such that a stable behavior emerges.
	</p>
	
	<video controls width="750" class="center">
		<source src="videos/grid_and_envi/noise_no_damage_small.mp4"
				type="video/mp4" >
		Sorry, your browser doesn't support embedded videos.
	</video>
	<div class="caption">
		A neural CA controls a cartpole agent for 500 steps with noisy update.
	</div>
	<p>
		Here is an overview of the cartpole agent abilities when the neural CA is subject to noisy updates.
	</p>
	

	
	<p>
		<div>
		<video controls width="750" class="center">
			<source src="videos/mosaics/mosaic_damageFalse_noiseTrue_small.mp4"
					type="video/mp4" >
			Sorry, your browser doesn't support embedded videos.
		</video>
		</div>
		
		<div class="caption">
			9 independent runs of 1000 steps of the neural CA cartpole agent with noisy update. <br>
		</div>
	</p>
	
	
	
	<h6> Resistance to input deletion </h6>
	<p>
	One of the particularities of this neural CA model is its flexibility. For instance, the number of inputs and
		outputs can vary without changing the architecture. We only have to replace input or output cells with intermediate ones.
	</p>
	<p>
		We were interested in exploring this flexibility and whether our model showed robustness to input deletion.
		Because observation from the cartpole environment are encoded redundantly, we tested if it was able 
		to exploit this particularity even if it was not trained for this.
	
	</p>
	<p>
		In the video below, we can observe the consequences of deleting each input. Each column correspond to one observation type,
		each row corresponds to the first or the second input cell encoding this observation being deleted.
	</p>
	
	<div>
		<video controls width="750" class="center">
			<source src="videos/mosaics/mosaic_deleted_cells_with_text.mp4"
					type="video/mp4" >
			Sorry, your browser doesn't support embedded videos.
		</video>
	</div>
	
	<div class="caption">
		Simulation of 1000 cartpole steps with one input deleted. We also added noise and damage after update. 
		Each column correspond to one observation type. Each row correspond to the first or the second input 
		cell encoding this observation being deleted. <br>
	</div>
	
	<p>
		The mean scores on 25 independent runs
		for each input deletion are summarized in the table below.
	</p>
	

	<table>
	  <thead>
		<tr>
		  <th> </th>
		  <th>Cart position</th>
		  <th>Cart velocity</th>
		  <th>Pole angle</th>
		  <th>Pole angular velocity</th>
		</tr>
	  </thead>
	  <tbody>
		<tr>
		  <th> First input deleted </th>
		  <td> 814.1 &pm; 632</td>
		  <td> 293.4  &pm; 144</td>
		  <td> 924.6 &pm; 601</td>
		  <td> 267.2 &pm; 139</td>
		</tr>
		<tr>
		  <th>Second input deleted</th>
		  <td>814.6 &pm; 608</td>
		  <td>168.2 &pm; 46</td>
		  <td>53.6  &pm; 37</td>
		  <td>103.2 &pm; 30</td>
		</tr>
	  </tbody>
	</table>

	<div class="caption"> Mean score and standard deviation of 25 independent runs after each input deletion.
						  The CAs were perturbed with damage after update (on average one every 2 cartpole steps) and noisy update. </div>
	
	<p>
		The system seems to be dependent on a few inputs that seriously impairs performances such as the inputs encoding for pole angle and angular velocity, 
		while others seem not to affect significantly its abilities. We hypothesize that even if it has not been directly trained to be robust to input deletion,
		the robustness to damage and noise includes also adaptation to unseen perturbation.
	</p>
	
	<p>
		It seems that the inputs corresponding to the cart position do not affect by much the balancing abilities. So
		we experimented how the system will react to sensory deprivation by removing these two input cells such that the system has no longer access to this observation. 
		It is still able to maintain the pole balance for several thousands of steps (score of 2838.3 &pm; 1267 on 25 runs without noise and damage). 
		The reconfiguration of the grid can be observed in the video below.
	</p>
	
	<div>
		<video controls width="850" class="center">
			<source src="videos/grid_and_envi/cart_position_observation_removed.mp4"
					type="video/mp4" >
			Sorry, your browser doesn't support embedded videos.
		</video>
	</div>
	
	<div class="caption">
		The neural CA and the cartpole environment it controls. The input cells corresponding to the cart position
		have been deleted and replaced by intermediate cells. No noise nor damage were added. <br>
	</div>
	
	<h2> Discussion </h2>
		<p>
			In this work, we demonstrated that neural CA can be used as a differentiable black-box function
			in the context of Deep-Q learning. We used it to solve the simple cartpole problem. A future challenge
			would be to apply it in cases where the input and output dimensionality is much higher.
		</p>
		<p>
			The computing abilities of the CA were maintained over several hundreds of 
			thousand iterations, producing an emergent stable behavior in the environment it controls for thousands of steps. 
			Moreover the system obtained demonstrated life-like phenomena such as a developmental phase, regeneration after damage,
			stability despite a noisy environment and robustness to unseen disruption such as input deletion.
			We can imagine that these abilities could be useful in a decentralized hardware where each cell is 
			processed by an independent computing unit.
		</p>
		<p>
			This is a step toward designing intelligent systems that incorporate 
			self-organization abilities that are for now reserved to the living world.
		</p>
		
	<h2> Additional experiments </h2>
		In addition to the cartpole balancing problem, we explored other tasks and different variation of the neural CA model.
		Here is a short list of the other tasks we tried that relates to problems solved in a decentralized way
		by biological organisms.
		
		<ul>
			<li> Exploring an environment to find an output cell </li>
			<li> Following a gradient </li>
			<li> Computing boolean functions </li>
		</ul>
	
	<!--
	
	* Functional homeostasis
	* Indirect encoding of the way to solve the task
	* development throught local interaction -> could lead to adaptation and here robustness
	* low information encoding of complex task. The complexity can emerge in the spatial shape of the interaction
	 while the information encoding the local law are low info // genomic bottleneck
	* abstract computing substrate 
	* Growing / pruning of ANN
	* continuity growing / computing -> non neural cells precusor of neural activity -->
	 
	
	
	
  </div>
  </div>
  </body>