{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towards self-organized control\n",
    "### Train a neural cellular automata that controls a cart-pole agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by installing the tools needed: some packages to render the environment in the notebook as well as SelfOrgControl, our implementation of neural CA and the training procedure for the cart-pole task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/aVariengien/self-organized-control.git#subdirectory=code\n",
    "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import SelfOrgControl.NeuralCA as NCA\n",
    "from SelfOrgControl.NCA_DQN import DQNAgent\n",
    "from SelfOrgControl.NeuralCAVisu import visualize_agent, show_influence_field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation of the model\n",
    "We first train the model to compute the mean of its 8 inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inp_cell_pos = [(11, 26),(25,20),(5,20),(19,6),(19,26),(5,12),(25,12) ,(11, 6)]\n",
    "out_cell_pos = [(13,16), (17,16)]\n",
    "\n",
    "lr = 5e-3\n",
    "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [1000, 5000], [lr, lr*0.1, lr*0.001])\n",
    "\n",
    "nca = NCA.TrainableNeuralCA(input_electrodes = inp_cell_pos,\n",
    "                            output_electrodes = out_cell_pos,\n",
    "                            grid_size=32,\n",
    "                            batch_size=16, channel_n=6,\n",
    "                            ca_steps_per_sample=(50,60),\n",
    "                            replace_proba=0.01,\n",
    "                            task_loss_w=0.5, grid_pool_size=100,\n",
    "                            learning_rate=lr,\n",
    "                            repeat_input=1, #there is no redondancy\n",
    "                            torus_boundaries=False,\n",
    "                            penalize_overflow=True, overflow_w = 1e2,\n",
    "                            use_hidden_inputs=True, perturb_io_pos=True,\n",
    "                            add_noise=False, damage=True,\n",
    "                            nb_hid_range=(0,0), move_rad=0, proba_move=0.0)\n",
    "print(nca.neuralCA.dmodel.summary())\n",
    "\n",
    "\n",
    "inputs_b = (np.random.random((4000,16,8)) - 0.5)*2\n",
    "targets_b = np.repeat(np.expand_dims(np.mean(inputs_b, axis=-1),-1),2,axis=-1)*4\n",
    "#we add a factor 4 to get on average a greater amplitude in the output values to\n",
    "# predict\n",
    "\n",
    "\n",
    "nca.fit(inputs_b, targets_b, verbose=True, use_batch=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of the initiaisation phase\n",
    "Plot the loss curve to ensure that something has been learned. \n",
    "The log10 of the loss should be around -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nca.plot_losses() #plot the loss curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dynamics of the outputs on 5 samples to check that the output\n",
    "is responding to the inputs values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = nca.plot_io_signals(55,inputs_b[:5,0,:], targets_b[:5,0,:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the initialisation phase worked as excpected, save the model and go to the Deep-Q learning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nca.neuralCA.dmodel.save_weights(\"compute_mean_initialisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent()\n",
    "# define the hyperparameters of the deep-q learning algo.\n",
    "agent.epsilon = 1.\n",
    "agent.epsilon_decay = 0.999\n",
    "#the agent batch size is the number of transitions sampled from the memory at each \n",
    "#replay. They will be divided in agent.batch_size/agent.model.batch_size batches \n",
    "#for the training of the neural CA\n",
    "\n",
    "agent.batch_size = 128\n",
    "\n",
    "lr = 5e-3\n",
    "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [1000,10000], [lr, lr*0.1, lr*0.001])\n",
    "\n",
    "\n",
    "# The role of each input and output cell\n",
    "\n",
    "inp_cell_pos = [(11, 26),(25,20), # Cart position \n",
    "                (5,20),(19,6),    # Cart velocity \n",
    "                (19,26),(5,13),   # Pole angle\n",
    "                (25,12) ,(11, 6)] # Pole angular velocity\n",
    "\n",
    "out_cell_pos = [(13,16), # Expected reward if it pushes left\n",
    "                (17,16)] # Expected reward if it pushes right\n",
    "\n",
    "# define the NCA model to train\n",
    "agent.model = NCA.TrainableNeuralCA(input_electrodes = inp_cell_pos,\n",
    "                            output_electrodes = out_cell_pos,\n",
    "                            grid_size=32,\n",
    "                            batch_size=16, channel_n=6,\n",
    "                            ca_steps_per_sample=(50,60),\n",
    "                            replace_proba=0.01,\n",
    "                            task_loss_w=0.5, grid_pool_size=100,\n",
    "                            learning_rate=lr,\n",
    "                            repeat_input=2, #Redondancy is used here, each input is linked to 2 input cells\n",
    "                            torus_boundaries=False,\n",
    "                            penalize_overflow=True, overflow_w = 1e2,\n",
    "                            use_hidden_inputs=True, perturb_io_pos=True,\n",
    "                            add_noise=False, damage=True,\n",
    "                            nb_hid_range=(0,0), move_rad=0, proba_move=0.0)\n",
    "\n",
    "# initialize using the previously trained parameters\n",
    "agent.model.neuralCA.dmodel.load_weights(\"compute_mean_initialisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the agent\n",
    "Because the deep-q learning algorithm optimizes the model to learn a proxy for the policy, the decreasing of the loss doesn't always means that the score of the agent will increase. It sometimes fail to find a good agent despite the log 10 of loss reaching ~ -1.8.\n",
    "\n",
    "It will be sometimes necessary to restart the learning process from the begining to find a good performing model (score > 300). The best performing model can be deceptive even after 700 replays, when epsilon has decay below 0.05. Around 1 over 2 runs of training lead to agents presenting good performance.\n",
    "\n",
    "If the score is > 100, you can be sure that *something* has been learned: for a random policy the average score is 21 and the probability of getting a score greater than 100 is less than 0.0005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_for_test = DQNAgent()\n",
    "\n",
    "# define the NCA model to test\n",
    "agent_for_test.model = NCA.TrainableNeuralCA(input_electrodes = inp_cell_pos,\n",
    "                            output_electrodes = out_cell_pos,\n",
    "                            grid_size=32,\n",
    "                            batch_size=1, channel_n=6, #we use batch_size =1 to speed up the computation for the test phase\n",
    "                            ca_steps_per_sample=(50,60),\n",
    "                            replace_proba=0.01,\n",
    "                            task_loss_w=0.5, grid_pool_size=1,\n",
    "                            learning_rate=lr,\n",
    "                            repeat_input=2, #Redondancy is used here, each input is linked to 2 input cells\n",
    "                            torus_boundaries=False,\n",
    "                            penalize_overflow=True, overflow_w = 1e2,\n",
    "                            use_hidden_inputs=True, perturb_io_pos=True,\n",
    "                            add_noise=False, damage=False,\n",
    "                            nb_hid_range=(0,0), move_rad=0, proba_move=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_for_test.model.neuralCA.dmodel.load_weights(agent.best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pretrained model\n",
    "You can execute the cells belove to load a model pretrained to solve the cart-pole problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/aVariengien/self-organized-control/main/code/PretrainedModels.zip\n",
    "!unzip PretrainedModels.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Available models: model 1,2 and 3\n",
    "agent_for_test.model.neuralCA.dmodel.load_weights(\"PretrainedModels/model2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the learned policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start a virtual display to be able to render the cart-pole environment in Colab\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_for_test.test(nb_episode=1, verbose=0, render=False, render_for_colab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_for_test.test(nb_episode=5, verbose=1, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the neural CA\n",
    "\n",
    "The images will be saved in an automatically created directory called \"agent_video_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a video of the cart-pole agent and the NCA side to side\n",
    "agent_for_test.env.auto_reset = True # We make the environment reset automatically if the pole fall\n",
    "visualize_agent(agent_for_test, 100, output_video=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the influence field of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_,sensors  = agent_for_test.test(return_sensors=True, verbose=False, render=False, nb_episode=1, fix_nb_step=100)\n",
    "sensors_list = []\n",
    "\n",
    "for i in range(len(sensors)):\n",
    "    sensors_list.append(sensors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations = []\n",
    "inp_cell_pos = [(11, 26),(25,20),(5,20),(19,6),(19,26),(5,12),(25,12) ,(11, 6)]\n",
    "for i in range(8):\n",
    "    dev = show_influence_field(agent_for_test.model,inputs_to_sample=sensors_list, \n",
    "                                nb_rounds=10, perturb_range=(-1,1), \n",
    "                                perturb_input=[i],\n",
    "                                normalize_mean=True)\n",
    "    deviations.append(dev)\n",
    "    print(\"\\r\"+str(i+1)+ \"/8\", end=\"\")\n",
    "no_pertub_dev = show_influence_field(agent_for_test.model,inputs_to_sample=sensors_list, \n",
    "                                nb_rounds=10, perturb_range=(1.,1.), \n",
    "                                perturb_input=[],\n",
    "                                normalize_mean=True)\n",
    "print(\"\\rdone.\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "titles = [\"Cart position\", \"Cart velocity\", \"Pole angle\", \"Pole angular velocity\", \"No perturbation\"]\n",
    "min_val = -1.6\n",
    "max_val= 0.2\n",
    "\n",
    "axes = []\n",
    "fig=plt.figure(figsize=(20,8))\n",
    "for i in range(4):\n",
    "    col = []\n",
    "    for j in range(2):\n",
    "        col.append(plt.subplot2grid((4,10), [j*2,i*2], 2, 2, fig=fig))\n",
    "    axes.append(col)\n",
    "    \n",
    "axes.append(plt.subplot2grid((4,10), [1,8], 2, 2 , fig=fig))\n",
    "\n",
    "inp_cell_pos = [(11, 26),(25,20),(5,20),(19,6),(19,26),(5,13),(25,12) ,(11, 6)]\n",
    "log_dev = np.log10(deviations)\n",
    "for i in range(0,4):\n",
    "    for j in range(2):\n",
    "        axes[i][j].axis(\"off\")\n",
    "        m  = axes[i][j].matshow(log_dev[2*i+j], vmin=min_val, vmax=max_val)\n",
    "\n",
    "        axes[i][j].plot([inp_cell_pos[2*i+j][1]], [inp_cell_pos[2*i+j][0]], marker=\"x\", color='red')\n",
    "        axes[i][j].plot([16,16], [17,13], marker=\".\",linestyle=\"none\", color=\"black\", alpha=0.5)\n",
    "        if j == 0:\n",
    "            axes[i][j].set_title(titles[i],  pad=-200)\n",
    "        \n",
    "axes[4].set_title(titles[4])\n",
    "axes[4].axis(\"off\")\n",
    "m= axes[4].matshow(np.log10(no_pertub_dev), vmin=min_val, vmax=max_val) \n",
    "axes[4].plot([16,16], [17,13], marker=\".\",linestyle=\"none\", color=\"black\", alpha=0.5)\n",
    "divider = make_axes_locatable(axes[4])\n",
    "cax = divider.new_horizontal(size=\"5%\", pad=0.05)\n",
    "fig.add_axes(cax)\n",
    "fig.colorbar(m, cax=cax)\n",
    "    \n",
    "fig.suptitle(\"Log 10 of the deviation after perturbation\", fontsize=15, y=1.05)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
